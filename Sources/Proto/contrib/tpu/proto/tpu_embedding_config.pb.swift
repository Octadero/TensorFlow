// DO NOT EDIT.
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: tensorflow/contrib/tpu/proto/tpu_embedding_config.proto
//
// For information on using the generated types, please see the documenation:
//   https://github.com/apple/swift-protobuf/

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that your are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// The TPUEmbeddingConfiguration contains specification of TPU Embedding lookups
/// and gradient updates separate from the TF Graph.
public struct Tensorflow_Tpu_TPUEmbeddingConfiguration {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var modelMode: Tensorflow_Tpu_TPUEmbeddingConfiguration.ModelMode = .invalid

  /// num_hosts is the number of host CPU systems in the training/inference job.
  /// Each embedding table must be sharded into num_hosts separate Variables,
  /// placed separately on the num_hosts CPU devices in the cluster. Sharding
  /// will be performed equivalently to the 'div' sharding_strategy option of
  /// embedding_lookup() and embedding_lookup_sparse().
  public var numHosts: Int32 = 0

  /// The total number of TensorNodes. This is equal to num_hosts times the
  /// number of TensorNodes attached to each host.
  public var numTensornodes: Int32 = 0

  /// The number of training examples per TensorNode.
  public var batchSize: Int32 = 0

  public var tableConfig: [Tensorflow_Tpu_TPUEmbeddingConfiguration.TPUEmbeddingTable] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// model_mode specifies whether the model is to be run in training or
  /// inference. In inference mode, gradient updates to embedding tables are not
  /// performed.
  public enum ModelMode: SwiftProtobuf.Enum {
    public typealias RawValue = Int
    case invalid // = 0
    case training // = 1
    case inference // = 2
    case UNRECOGNIZED(Int)

    public init() {
      self = .invalid
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .invalid
      case 1: self = .training
      case 2: self = .inference
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .invalid: return 0
      case .training: return 1
      case .inference: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  public struct GradientDescentOptimizer {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    public var learningRate: Float = 0

    public var unknownFields = SwiftProtobuf.UnknownStorage()

    public init() {}
  }

  public struct AdagradOptimizer {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    public var learningRate: Float = 0

    public var initialAccumulator: Float = 0

    public var unknownFields = SwiftProtobuf.UnknownStorage()

    public init() {}
  }

  /// Each Embedding
  public struct TPUEmbeddingTable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Name of the embedding table. This will be used to name Variables in the
    /// Tensorflow Graph.
    public var name: String {
      get {return _storage._name}
      set {_uniqueStorage()._name = newValue}
    }

    /// Number of rows of the embedding table. The Variable created to hold the
    /// learned embedding table values will have shape (num_rows, width).
    public var numRows: Int32 {
      get {return _storage._numRows}
      set {_uniqueStorage()._numRows = newValue}
    }

    /// Width of the embedding table. The Variable created to hold the
    /// learned embedding table values will have shape (num_rows, width).
    public var width: Int32 {
      get {return _storage._width}
      set {_uniqueStorage()._width = newValue}
    }

    /// Number of distinct embedding activation vectors per training example
    /// produced by lookups into this table during model evaluation. For each
    /// table, the Graph will receive an activations Tensor of shape
    ///   (batch_size * table.num_features, table.width).
    /// For example, num_features = 1 produces equivalent behavior to a single
    /// tf.nn.embedding_lookup() call. In the case of 'multivalent' embeddings,
    /// (i.e. tf.nn.embedding_lookup_sparse()) which compute weighted averages of
    /// embedding table rows, num_features is the number of vectors produced
    /// after averaging. In sequence models num_features is typically equal
    /// to the sequence length, since each sequence element must be represented
    /// separately to the convolutional or recurrent network.
    public var numFeatures: Int32 {
      get {return _storage._numFeatures}
      set {_uniqueStorage()._numFeatures = newValue}
    }

    public var optimizer: OneOf_Optimizer? {
      get {return _storage._optimizer}
      set {_uniqueStorage()._optimizer = newValue}
    }

    public var gradientDescent: Tensorflow_Tpu_TPUEmbeddingConfiguration.GradientDescentOptimizer {
      get {
        if case .gradientDescent(let v)? = _storage._optimizer {return v}
        return Tensorflow_Tpu_TPUEmbeddingConfiguration.GradientDescentOptimizer()
      }
      set {_uniqueStorage()._optimizer = .gradientDescent(newValue)}
    }

    public var adagrad: Tensorflow_Tpu_TPUEmbeddingConfiguration.AdagradOptimizer {
      get {
        if case .adagrad(let v)? = _storage._optimizer {return v}
        return Tensorflow_Tpu_TPUEmbeddingConfiguration.AdagradOptimizer()
      }
      set {_uniqueStorage()._optimizer = .adagrad(newValue)}
    }

    public var unknownFields = SwiftProtobuf.UnknownStorage()

    public enum OneOf_Optimizer: Equatable {
      case gradientDescent(Tensorflow_Tpu_TPUEmbeddingConfiguration.GradientDescentOptimizer)
      case adagrad(Tensorflow_Tpu_TPUEmbeddingConfiguration.AdagradOptimizer)

      public static func ==(lhs: Tensorflow_Tpu_TPUEmbeddingConfiguration.TPUEmbeddingTable.OneOf_Optimizer, rhs: Tensorflow_Tpu_TPUEmbeddingConfiguration.TPUEmbeddingTable.OneOf_Optimizer) -> Bool {
        switch (lhs, rhs) {
        case (.gradientDescent(let l), .gradientDescent(let r)): return l == r
        case (.adagrad(let l), .adagrad(let r)): return l == r
        default: return false
        }
      }
    }

    public init() {}

    fileprivate var _storage = _StorageClass.defaultInstance
  }

  public init() {}
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "tensorflow.tpu"

extension Tensorflow_Tpu_TPUEmbeddingConfiguration: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TPUEmbeddingConfiguration"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "model_mode"),
    2: .standard(proto: "num_hosts"),
    3: .standard(proto: "num_tensornodes"),
    4: .standard(proto: "batch_size"),
    5: .standard(proto: "table_config"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      switch fieldNumber {
      case 1: try decoder.decodeSingularEnumField(value: &self.modelMode)
      case 2: try decoder.decodeSingularInt32Field(value: &self.numHosts)
      case 3: try decoder.decodeSingularInt32Field(value: &self.numTensornodes)
      case 4: try decoder.decodeSingularInt32Field(value: &self.batchSize)
      case 5: try decoder.decodeRepeatedMessageField(value: &self.tableConfig)
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.modelMode != .invalid {
      try visitor.visitSingularEnumField(value: self.modelMode, fieldNumber: 1)
    }
    if self.numHosts != 0 {
      try visitor.visitSingularInt32Field(value: self.numHosts, fieldNumber: 2)
    }
    if self.numTensornodes != 0 {
      try visitor.visitSingularInt32Field(value: self.numTensornodes, fieldNumber: 3)
    }
    if self.batchSize != 0 {
      try visitor.visitSingularInt32Field(value: self.batchSize, fieldNumber: 4)
    }
    if !self.tableConfig.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.tableConfig, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public func _protobuf_generated_isEqualTo(other: Tensorflow_Tpu_TPUEmbeddingConfiguration) -> Bool {
    if self.modelMode != other.modelMode {return false}
    if self.numHosts != other.numHosts {return false}
    if self.numTensornodes != other.numTensornodes {return false}
    if self.batchSize != other.batchSize {return false}
    if self.tableConfig != other.tableConfig {return false}
    if unknownFields != other.unknownFields {return false}
    return true
  }
}

extension Tensorflow_Tpu_TPUEmbeddingConfiguration.ModelMode: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "INVALID"),
    1: .same(proto: "TRAINING"),
    2: .same(proto: "INFERENCE"),
  ]
}

extension Tensorflow_Tpu_TPUEmbeddingConfiguration.GradientDescentOptimizer: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = Tensorflow_Tpu_TPUEmbeddingConfiguration.protoMessageName + ".GradientDescentOptimizer"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "learning_rate"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      switch fieldNumber {
      case 1: try decoder.decodeSingularFloatField(value: &self.learningRate)
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.learningRate != 0 {
      try visitor.visitSingularFloatField(value: self.learningRate, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public func _protobuf_generated_isEqualTo(other: Tensorflow_Tpu_TPUEmbeddingConfiguration.GradientDescentOptimizer) -> Bool {
    if self.learningRate != other.learningRate {return false}
    if unknownFields != other.unknownFields {return false}
    return true
  }
}

extension Tensorflow_Tpu_TPUEmbeddingConfiguration.AdagradOptimizer: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = Tensorflow_Tpu_TPUEmbeddingConfiguration.protoMessageName + ".AdagradOptimizer"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "learning_rate"),
    2: .standard(proto: "initial_accumulator"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      switch fieldNumber {
      case 1: try decoder.decodeSingularFloatField(value: &self.learningRate)
      case 2: try decoder.decodeSingularFloatField(value: &self.initialAccumulator)
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.learningRate != 0 {
      try visitor.visitSingularFloatField(value: self.learningRate, fieldNumber: 1)
    }
    if self.initialAccumulator != 0 {
      try visitor.visitSingularFloatField(value: self.initialAccumulator, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public func _protobuf_generated_isEqualTo(other: Tensorflow_Tpu_TPUEmbeddingConfiguration.AdagradOptimizer) -> Bool {
    if self.learningRate != other.learningRate {return false}
    if self.initialAccumulator != other.initialAccumulator {return false}
    if unknownFields != other.unknownFields {return false}
    return true
  }
}

extension Tensorflow_Tpu_TPUEmbeddingConfiguration.TPUEmbeddingTable: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = Tensorflow_Tpu_TPUEmbeddingConfiguration.protoMessageName + ".TPUEmbeddingTable"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    3: .standard(proto: "num_rows"),
    4: .same(proto: "width"),
    5: .standard(proto: "num_features"),
    6: .standard(proto: "gradient_descent"),
    7: .same(proto: "adagrad"),
  ]

  fileprivate class _StorageClass {
    var _name: String = String()
    var _numRows: Int32 = 0
    var _width: Int32 = 0
    var _numFeatures: Int32 = 0
    var _optimizer: Tensorflow_Tpu_TPUEmbeddingConfiguration.TPUEmbeddingTable.OneOf_Optimizer?

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _name = source._name
      _numRows = source._numRows
      _width = source._width
      _numFeatures = source._numFeatures
      _optimizer = source._optimizer
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        switch fieldNumber {
        case 1: try decoder.decodeSingularStringField(value: &_storage._name)
        case 3: try decoder.decodeSingularInt32Field(value: &_storage._numRows)
        case 4: try decoder.decodeSingularInt32Field(value: &_storage._width)
        case 5: try decoder.decodeSingularInt32Field(value: &_storage._numFeatures)
        case 6:
          var v: Tensorflow_Tpu_TPUEmbeddingConfiguration.GradientDescentOptimizer?
          if let current = _storage._optimizer {
            try decoder.handleConflictingOneOf()
            if case .gradientDescent(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._optimizer = .gradientDescent(v)}
        case 7:
          var v: Tensorflow_Tpu_TPUEmbeddingConfiguration.AdagradOptimizer?
          if let current = _storage._optimizer {
            try decoder.handleConflictingOneOf()
            if case .adagrad(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._optimizer = .adagrad(v)}
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if !_storage._name.isEmpty {
        try visitor.visitSingularStringField(value: _storage._name, fieldNumber: 1)
      }
      if _storage._numRows != 0 {
        try visitor.visitSingularInt32Field(value: _storage._numRows, fieldNumber: 3)
      }
      if _storage._width != 0 {
        try visitor.visitSingularInt32Field(value: _storage._width, fieldNumber: 4)
      }
      if _storage._numFeatures != 0 {
        try visitor.visitSingularInt32Field(value: _storage._numFeatures, fieldNumber: 5)
      }
      switch _storage._optimizer {
      case .gradientDescent(let v)?:
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      case .adagrad(let v)?:
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      case nil: break
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public func _protobuf_generated_isEqualTo(other: Tensorflow_Tpu_TPUEmbeddingConfiguration.TPUEmbeddingTable) -> Bool {
    if _storage !== other._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((_storage, other._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let other_storage = _args.1
        if _storage._name != other_storage._name {return false}
        if _storage._numRows != other_storage._numRows {return false}
        if _storage._width != other_storage._width {return false}
        if _storage._numFeatures != other_storage._numFeatures {return false}
        if _storage._optimizer != other_storage._optimizer {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if unknownFields != other.unknownFields {return false}
    return true
  }
}
